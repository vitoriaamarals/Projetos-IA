{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import time\n",
        "import tracemalloc\n",
        "\n",
        "# 1. Carregar a base Iris\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"Dados carregados e divididos com sucesso!\")\n",
        "print(f\"Formato do conjunto de treino: {X_train.shape}\")\n",
        "print(f\"Formato do conjunto de teste: {X_test.shape}\")\n",
        "\n",
        "k_values = [1, 3, 5, 7]\n",
        "results_manual = {}\n",
        "results_sklearn = {}"
      ],
      "metadata": {
        "id": "539qB9y2kr6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Implementação KNN manual\n",
        "def euclidean_distance(a, b):\n",
        "    return np.sqrt(np.sum((a - b) ** 2))\n",
        "\n",
        "def knn_predict(X_train, y_train, x_test, k):\n",
        "    distances = [euclidean_distance(x_test, x_train) for x_train in X_train]\n",
        "    k_indices = np.argsort(distances)[:k]\n",
        "    k_labels = [y_train[i] for i in k_indices]\n",
        "    most_common = Counter(k_labels).most_common(1)[0][0]\n",
        "    return most_common\n",
        "\n",
        "def evaluate_knn_manual(k):\n",
        "    tracemalloc.start()\n",
        "    start_time = time.time()\n",
        "\n",
        "    y_pred = [knn_predict(X_train, y_train, x, k) for x in X_test]\n",
        "\n",
        "    end_time = time.time()\n",
        "    current, peak = tracemalloc.get_traced_memory()\n",
        "    tracemalloc.stop()\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred, average='macro')\n",
        "    rec = recall_score(y_test, y_pred, average='macro')\n",
        "    f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "    # Relatório completo\n",
        "    print(f\"\\nKNN Manual k={k}\")\n",
        "    print(\"Acurácia:\", acc)\n",
        "    print(\"Precisão (macro):\", prec)\n",
        "    print(\"Revocação (macro):\", rec)\n",
        "    print(\"F1-score (macro):\", f1)\n",
        "    print(\"Relatório completo:\\n\", classification_report(y_test, y_pred, target_names=iris.target_names))\n",
        "\n",
        "    # Matriz de confusão\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    plt.figure(figsize=(5,4))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
        "    plt.title(f\"Matriz de confusão - KNN Manual (k={k})\")\n",
        "    plt.ylabel(\"Verdadeiro\")\n",
        "    plt.xlabel(\"Previsto\")\n",
        "    plt.show()\n",
        "\n",
        "    return acc, prec, rec, f1, end_time - start_time, peak/1024\n",
        "\n",
        "# AVALIAÇÃO MANUAL\n",
        "print(\"AVALIAÇÃO DO KNN MANUAL\")\n",
        "for k in k_values:\n",
        "    results_manual[k] = evaluate_knn_manual(k)"
      ],
      "metadata": {
        "id": "hQieQ-XlkuqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. KNN Sklearn\n",
        "def evaluate_knn_sklearn(k):\n",
        "    tracemalloc.start()\n",
        "    start_time = time.time()\n",
        "\n",
        "    model = KNeighborsClassifier(n_neighbors=k)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    end_time = time.time()\n",
        "    current, peak = tracemalloc.get_traced_memory()\n",
        "    tracemalloc.stop()\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred, average='macro')\n",
        "    rec = recall_score(y_test, y_pred, average='macro')\n",
        "    f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "    # Relatório completo\n",
        "    print(f\"\\nKNN Sklearn k={k}\")\n",
        "    print(\"Acurácia:\", acc)\n",
        "    print(\"Precisão (macro):\", prec)\n",
        "    print(\"Revocação (macro):\", rec)\n",
        "    print(\"F1-score (macro):\", f1)\n",
        "    print(\"Relatório completo:\\n\", classification_report(y_test, y_pred, target_names=iris.target_names))\n",
        "\n",
        "    # Matriz de confusão\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    plt.figure(figsize=(5,4))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Greens\", xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
        "    plt.title(f\"Matriz de confusão - KNN Sklearn (k={k})\")\n",
        "    plt.ylabel(\"Verdadeiro\")\n",
        "    plt.xlabel(\"Previsto\")\n",
        "    plt.show()\n",
        "\n",
        "    return acc, prec, rec, f1, end_time - start_time, peak/1024\n",
        "\n",
        "# AVALIAÇÃO SKLEARN\n",
        "print(\"AVALIAÇÃO DO KNN SKLEARN\")\n",
        "for k in k_values:\n",
        "    results_sklearn[k] = evaluate_knn_sklearn(k)"
      ],
      "metadata": {
        "id": "djziB68OkzuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Preparar dados para gráficos\n",
        "metrics = ['Acurácia', 'Precisão', 'Revocação', 'F1-score', 'Tempo(s)', 'Memória(KB)']\n",
        "manual_vals = {m: [] for m in metrics}\n",
        "sklearn_vals = {m: [] for m in metrics}\n",
        "\n",
        "for k in k_values:\n",
        "    acc, prec, rec, f1, t, mem = results_manual[k]\n",
        "    manual_vals['Acurácia'].append(acc)\n",
        "    manual_vals['Precisão'].append(prec)\n",
        "    manual_vals['Revocação'].append(rec)\n",
        "    manual_vals['F1-score'].append(f1)\n",
        "    manual_vals['Tempo(s)'].append(t)\n",
        "    manual_vals['Memória(KB)'].append(mem)\n",
        "\n",
        "    acc, prec, rec, f1, t, mem = results_sklearn[k]\n",
        "    sklearn_vals['Acurácia'].append(acc)\n",
        "    sklearn_vals['Precisão'].append(prec)\n",
        "    sklearn_vals['Revocação'].append(rec)\n",
        "    sklearn_vals['F1-score'].append(f1)\n",
        "    sklearn_vals['Tempo(s)'].append(t)\n",
        "    sklearn_vals['Memória(KB)'].append(mem)\n",
        "\n",
        "# 6. Função para plotar gráfico de barras\n",
        "def plot_bar(metric_name, manual, sklearn):\n",
        "    x = np.arange(len(k_values))\n",
        "    width = 0.35\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.bar(x - width/2, manual, width, label='Manual', color='skyblue')\n",
        "    plt.bar(x + width/2, sklearn, width, label='Sklearn', color='salmon')\n",
        "    plt.xticks(x, k_values)\n",
        "    plt.ylabel(metric_name)\n",
        "    plt.xlabel('Valor de k')\n",
        "    plt.title(f'Comparação de {metric_name} - KNN Manual vs Sklearn')\n",
        "    plt.legend()\n",
        "    # Adicionar um pequeno espaço no topo para melhor visualização\n",
        "    if max(manual) > 0 or max(sklearn) > 0:\n",
        "        plt.ylim(0, max(max(manual), max(sklearn)) * 1.15)\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.show()\n",
        "\n",
        "# 7. Gerar gráficos para cada métrica\n",
        "for metric in metrics:\n",
        "    plot_bar(metric, manual_vals[metric], sklearn_vals[metric])"
      ],
      "metadata": {
        "id": "6U3Q_biAk_Gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Análise comparativa textual\n",
        "def comparative_analysis(k_values, manual_vals, sklearn_vals):\n",
        "    print(\"\\nAnálise Comparativa Detalhada: KNN Manual vs Sklearn\\n\")\n",
        "    for i, k in enumerate(k_values):\n",
        "        print(f\"Para k={k}:\")\n",
        "        for metric in metrics:\n",
        "            manual_metric = manual_vals[metric][i]\n",
        "            sklearn_metric = sklearn_vals[metric][i]\n",
        "\n",
        "            # Formatação para melhor leitura\n",
        "            format_str = \".6f\" if metric in ['Tempo(s)', 'Memória(KB)'] else \".4f\"\n",
        "\n",
        "            if metric in ['Tempo(s)', 'Memória(KB)']:\n",
        "                better = \"Sklearn\" if sklearn_metric < manual_metric else \"Manual\"\n",
        "                print(f\"  - {metric:<12}: Manual={manual_metric:{format_str}}, Sklearn={sklearn_metric:{format_str}} -> Melhor: {better}\")\n",
        "            else:\n",
        "                if np.isclose(manual_metric, sklearn_metric):\n",
        "                    better = \"Empate\"\n",
        "                else:\n",
        "                    better = \"Sklearn\" if sklearn_metric > manual_metric else \"Manual\"\n",
        "                print(f\"  - {metric:<12}: Manual={manual_metric:{format_str}}, Sklearn={sklearn_metric:{format_str}} -> Melhor: {better}\")\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "comparative_analysis(k_values, manual_vals, sklearn_vals)"
      ],
      "metadata": {
        "id": "Z-j3TKaVlzMf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}